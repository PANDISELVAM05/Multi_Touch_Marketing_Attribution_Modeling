{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438c5530",
   "metadata": {},
   "source": [
    "### Data_Cleaning1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bad6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  Campaign_ID    Channel_Name    Medium        Date     Cost  Impressions  \\\n",
      "0   CAMP_3756  Organic Search  Referral  17-12-2024   132.68         8204   \n",
      "1   CAMP_2957         YouTube   Organic  16-11-2024   933.30        42696   \n",
      "2   CAMP_6049  Organic Search      Paid  07-02-2025   109.88        44616   \n",
      "3   CAMP_8874         YouTube    Social  24-03-2025  2180.59        42768   \n",
      "4   CAMP_1106        LinkedIn   Organic  08-10-2025  1770.62        29371   \n",
      "\n",
      "   Clicks  Conversions   Revenue  totalmedium  \n",
      "0     513          154  27371.77            1  \n",
      "1    1097          149   4281.78            2  \n",
      "2    1360          479  20622.16            3  \n",
      "3     757          115  21483.62            4  \n",
      "4     955          155  18652.77            5  \n",
      "     Campaign_ID    Channel_Name    Medium        Date     Cost  Impressions  \\\n",
      "9995   CAMP_4564  Organic Search    Social  05-11-2024   266.37         2025   \n",
      "9996   CAMP_2714         Twitter  Referral  24-07-2025  1133.79        18113   \n",
      "9997   CAMP_5491         Twitter      Paid  08-02-2025   714.38        42127   \n",
      "9998   CAMP_5616       Instagram    Social  08-09-2025  1009.04        24695   \n",
      "9999   CAMP_6982  Organic Search    Social  11-03-2025   124.39        45279   \n",
      "\n",
      "      Clicks  Conversions   Revenue  totalmedium  \n",
      "9995     149           36   6501.31         1212  \n",
      "9996    1199           46   6975.43         1213  \n",
      "9997    3826           49   4190.42         1214  \n",
      "9998    1667          144  25968.37         1215  \n",
      "9999     553           25   4905.15         1216  \n",
      "\n",
      "\n",
      "\n",
      "dataset columns:\n",
      "Index(['Campaign_ID', 'Channel_Name', 'Medium', 'Date', 'Cost', 'Impressions',\n",
      "       'Clicks', 'Conversions', 'Revenue', 'totalmedium'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Data Types:\n",
      "Campaign_ID      object\n",
      "Channel_Name     object\n",
      "Medium           object\n",
      "Date             object\n",
      "Cost            float64\n",
      "Impressions       int64\n",
      "Clicks            int64\n",
      "Conversions       int64\n",
      "Revenue         float64\n",
      "totalmedium       int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Missing Values in Each Column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Campaign_ID   10000 non-null  object \n",
      " 1   Channel_Name  10000 non-null  object \n",
      " 2   Medium        10000 non-null  object \n",
      " 3   Date          10000 non-null  object \n",
      " 4   Cost          10000 non-null  float64\n",
      " 5   Impressions   10000 non-null  int64  \n",
      " 6   Clicks        10000 non-null  int64  \n",
      " 7   Conversions   10000 non-null  int64  \n",
      " 8   Revenue       10000 non-null  float64\n",
      " 9   totalmedium   10000 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 781.4+ KB\n",
      "None\n",
      "Campaign_ID     0\n",
      "Channel_Name    0\n",
      "Medium          0\n",
      "Date            0\n",
      "Cost            0\n",
      "Impressions     0\n",
      "Clicks          0\n",
      "Conversions     0\n",
      "Revenue         0\n",
      "totalmedium     0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "After cleaning (removing rows with only special characters or NaN in any column):\n",
      "  Campaign_ID    Channel_Name    Medium        Date     Cost  Impressions  \\\n",
      "0   CAMP_3756  Organic Search  Referral  17-12-2024   132.68         8204   \n",
      "1   CAMP_2957         YouTube   Organic  16-11-2024   933.30        42696   \n",
      "2   CAMP_6049  Organic Search      Paid  07-02-2025   109.88        44616   \n",
      "3   CAMP_8874         YouTube    Social  24-03-2025  2180.59        42768   \n",
      "4   CAMP_1106        LinkedIn   Organic  08-10-2025  1770.62        29371   \n",
      "\n",
      "   Clicks  Conversions   Revenue  totalmedium  \n",
      "0     513          154  27371.77            1  \n",
      "1    1097          149   4281.78            2  \n",
      "2    1360          479  20622.16            3  \n",
      "3     757          115  21483.62            4  \n",
      "4     955          155  18652.77            5  \n",
      "\n",
      "\n",
      "\n",
      "Cleaned data saved to channel_cost.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandi selvam\\AppData\\Local\\Temp\\ipykernel_20996\\1532913749.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"channel_cost.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project2\\Dataset\\channel_cost_data.csv\"  \n",
    "df = pd.read_csv(file_path) \n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"channel_cost.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d727c6",
   "metadata": {},
   "source": [
    "### Data_Cleaning2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9bde37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  Transaction_ID  User_ID Conversion_Event Conversion_Timestamp  \\\n",
      "0     TXN_100000     6492         Download     25-09-2025 06:13   \n",
      "1     TXN_100001     6322          Upgrade     07-01-2025 18:02   \n",
      "2     TXN_100002     2626           Signup     08-01-2025 20:37   \n",
      "3     TXN_100003     3484         Purchase     07-08-2025 03:12   \n",
      "4     TXN_100004     6515         Download     24-11-2024 16:05   \n",
      "\n",
      "   Conversion_Value  \n",
      "0              0.00  \n",
      "1           2423.74  \n",
      "2              0.00  \n",
      "3           1750.09  \n",
      "4              0.00  \n",
      "     Transaction_ID  User_ID Conversion_Event Conversion_Timestamp  \\\n",
      "9995     TXN_109995     3336      Add_to_Cart     05-08-2025 15:30   \n",
      "9996     TXN_109996     8838           Signup     14-08-2025 09:45   \n",
      "9997     TXN_109997     4432           Signup     06-02-2025 05:33   \n",
      "9998     TXN_109998     7822         Purchase     12-08-2025 04:49   \n",
      "9999     TXN_109999     8412     Subscription     07-12-2024 02:16   \n",
      "\n",
      "      Conversion_Value  \n",
      "9995              0.00  \n",
      "9996              0.00  \n",
      "9997              0.00  \n",
      "9998           1697.05  \n",
      "9999            190.19  \n",
      "\n",
      "\n",
      "\n",
      "dataset columns:\n",
      "Index(['Transaction_ID', 'User_ID', 'Conversion_Event', 'Conversion_Timestamp',\n",
      "       'Conversion_Value'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Data Types:\n",
      "Transaction_ID           object\n",
      "User_ID                   int64\n",
      "Conversion_Event         object\n",
      "Conversion_Timestamp     object\n",
      "Conversion_Value        float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Missing Values in Each Column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Transaction_ID        10000 non-null  object \n",
      " 1   User_ID               10000 non-null  int64  \n",
      " 2   Conversion_Event      10000 non-null  object \n",
      " 3   Conversion_Timestamp  10000 non-null  object \n",
      " 4   Conversion_Value      10000 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 390.8+ KB\n",
      "None\n",
      "Transaction_ID          0\n",
      "User_ID                 0\n",
      "Conversion_Event        0\n",
      "Conversion_Timestamp    0\n",
      "Conversion_Value        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "After cleaning (removing rows with only special characters or NaN in any column):\n",
      "  Transaction_ID  User_ID Conversion_Event Conversion_Timestamp  \\\n",
      "0     TXN_100000     6492         Download     25-09-2025 06:13   \n",
      "1     TXN_100001     6322          Upgrade     07-01-2025 18:02   \n",
      "2     TXN_100002     2626           Signup     08-01-2025 20:37   \n",
      "3     TXN_100003     3484         Purchase     07-08-2025 03:12   \n",
      "4     TXN_100004     6515         Download     24-11-2024 16:05   \n",
      "\n",
      "   Conversion_Value  \n",
      "0              0.00  \n",
      "1           2423.74  \n",
      "2              0.00  \n",
      "3           1750.09  \n",
      "4              0.00  \n",
      "\n",
      "\n",
      "\n",
      "Cleaned data saved to conversion.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandi selvam\\AppData\\Local\\Temp\\ipykernel_20996\\562356518.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"conversion.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project2\\Dataset\\conversion_data.csv\"  \n",
    "df = pd.read_csv(file_path) \n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"conversion.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135b7e9",
   "metadata": {},
   "source": [
    "### Data_Cleanign3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3daab8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  Customer_ID   Location Subscription_Plan  Total_Purchases  \\\n",
      "0  CUST_00001  Bangalore        Enterprise                7   \n",
      "1  CUST_00002    Kolkata        Enterprise                3   \n",
      "2  CUST_00003  Bangalore        Enterprise                3   \n",
      "3  CUST_00004       Pune        Enterprise                3   \n",
      "4  CUST_00005     Mumbai        Enterprise                9   \n",
      "\n",
      "  Last_Purchase_Date  Customer_Lifetime_Value  Subscription_Length_Months  \\\n",
      "0         06-08-2025                  1667.20                           7   \n",
      "1         05-09-2025                   737.11                           1   \n",
      "2         22-08-2025                   883.28                           6   \n",
      "3         05-06-2025                  1198.61                           4   \n",
      "4         20-09-2025                  2710.83                           3   \n",
      "\n",
      "  Churned                             Purchase_History_Dates  \\\n",
      "0      No  ['2024-11-15', '2025-01-23', '2025-02-19', '20...   \n",
      "1      No         ['2024-10-27', '2025-01-23', '2025-09-05']   \n",
      "2      No         ['2025-02-20', '2025-03-30', '2025-08-22']   \n",
      "3     Yes         ['2024-12-15', '2025-02-27', '2025-06-05']   \n",
      "4      No  ['2024-10-25', '2024-10-26', '2024-11-03', '20...   \n",
      "\n",
      "                                     Purchase_Values  totalplan  \n",
      "0  [45.01, 482.19, 288.16, 261.28, 109.25, 149.96...          1  \n",
      "1                           [143.92, 101.25, 491.94]          2  \n",
      "2                           [108.34, 471.59, 303.35]          3  \n",
      "3                           [290.08, 473.24, 435.29]          4  \n",
      "4  [45.79, 349.92, 458.36, 480.67, 187.48, 398.59...          5  \n",
      "     Customer_ID Location Subscription_Plan  Total_Purchases  \\\n",
      "9995  CUST_09996   Mumbai              Gold                1   \n",
      "9996  CUST_09997     Pune              Gold                3   \n",
      "9997  CUST_09998  Kolkata             Basic               10   \n",
      "9998  CUST_09999   Mumbai              Gold               10   \n",
      "9999  CUST_10000   Mumbai              Gold                4   \n",
      "\n",
      "     Last_Purchase_Date  Customer_Lifetime_Value  Subscription_Length_Months  \\\n",
      "9995         10-04-2025                   109.36                          12   \n",
      "9996         15-07-2025                   756.86                          10   \n",
      "9997         09-10-2025                  2306.33                           3   \n",
      "9998         14-10-2025                  2714.53                           8   \n",
      "9999         13-08-2025                   570.41                          12   \n",
      "\n",
      "     Churned                             Purchase_History_Dates  \\\n",
      "9995      No                                     ['2025-04-10']   \n",
      "9996      No         ['2024-11-10', '2025-06-02', '2025-07-15']   \n",
      "9997      No  ['2025-02-19', '2025-03-17', '2025-03-28', '20...   \n",
      "9998      No  ['2024-10-23', '2025-01-16', '2025-03-14', '20...   \n",
      "9999      No  ['2025-01-06', '2025-04-26', '2025-05-31', '20...   \n",
      "\n",
      "                                        Purchase_Values  totalplan  \n",
      "9995                                           [109.36]       1518  \n",
      "9996                           [163.68, 433.39, 159.79]       1519  \n",
      "9997  [120.34, 205.77, 443.75, 415.5, 52.1, 185.32, ...       1520  \n",
      "9998  [397.12, 117.15, 188.47, 288.37, 431.48, 490.5...       1521  \n",
      "9999                     [152.17, 45.35, 218.99, 153.9]       1522  \n",
      "\n",
      "\n",
      "\n",
      "dataset columns:\n",
      "Index(['Customer_ID', 'Location', 'Subscription_Plan', 'Total_Purchases',\n",
      "       'Last_Purchase_Date', 'Customer_Lifetime_Value',\n",
      "       'Subscription_Length_Months', 'Churned', 'Purchase_History_Dates',\n",
      "       'Purchase_Values', 'totalplan'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Data Types:\n",
      "Customer_ID                    object\n",
      "Location                       object\n",
      "Subscription_Plan              object\n",
      "Total_Purchases                 int64\n",
      "Last_Purchase_Date             object\n",
      "Customer_Lifetime_Value       float64\n",
      "Subscription_Length_Months      int64\n",
      "Churned                        object\n",
      "Purchase_History_Dates         object\n",
      "Purchase_Values                object\n",
      "totalplan                       int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Missing Values in Each Column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Customer_ID                 10000 non-null  object \n",
      " 1   Location                    10000 non-null  object \n",
      " 2   Subscription_Plan           10000 non-null  object \n",
      " 3   Total_Purchases             10000 non-null  int64  \n",
      " 4   Last_Purchase_Date          10000 non-null  object \n",
      " 5   Customer_Lifetime_Value     10000 non-null  float64\n",
      " 6   Subscription_Length_Months  10000 non-null  int64  \n",
      " 7   Churned                     10000 non-null  object \n",
      " 8   Purchase_History_Dates      10000 non-null  object \n",
      " 9   Purchase_Values             10000 non-null  object \n",
      " 10  totalplan                   10000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 859.5+ KB\n",
      "None\n",
      "Customer_ID                   0\n",
      "Location                      0\n",
      "Subscription_Plan             0\n",
      "Total_Purchases               0\n",
      "Last_Purchase_Date            0\n",
      "Customer_Lifetime_Value       0\n",
      "Subscription_Length_Months    0\n",
      "Churned                       0\n",
      "Purchase_History_Dates        0\n",
      "Purchase_Values               0\n",
      "totalplan                     0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "After cleaning (removing rows with only special characters or NaN in any column):\n",
      "  Customer_ID   Location Subscription_Plan  Total_Purchases  \\\n",
      "0  CUST_00001  Bangalore        Enterprise                7   \n",
      "1  CUST_00002    Kolkata        Enterprise                3   \n",
      "2  CUST_00003  Bangalore        Enterprise                3   \n",
      "3  CUST_00004       Pune        Enterprise                3   \n",
      "4  CUST_00005     Mumbai        Enterprise                9   \n",
      "\n",
      "  Last_Purchase_Date  Customer_Lifetime_Value  Subscription_Length_Months  \\\n",
      "0         06-08-2025                  1667.20                           7   \n",
      "1         05-09-2025                   737.11                           1   \n",
      "2         22-08-2025                   883.28                           6   \n",
      "3         05-06-2025                  1198.61                           4   \n",
      "4         20-09-2025                  2710.83                           3   \n",
      "\n",
      "  Churned                             Purchase_History_Dates  \\\n",
      "0      No  ['2024-11-15', '2025-01-23', '2025-02-19', '20...   \n",
      "1      No         ['2024-10-27', '2025-01-23', '2025-09-05']   \n",
      "2      No         ['2025-02-20', '2025-03-30', '2025-08-22']   \n",
      "3     Yes         ['2024-12-15', '2025-02-27', '2025-06-05']   \n",
      "4      No  ['2024-10-25', '2024-10-26', '2024-11-03', '20...   \n",
      "\n",
      "                                     Purchase_Values  totalplan  \n",
      "0  [45.01, 482.19, 288.16, 261.28, 109.25, 149.96...          1  \n",
      "1                           [143.92, 101.25, 491.94]          2  \n",
      "2                           [108.34, 471.59, 303.35]          3  \n",
      "3                           [290.08, 473.24, 435.29]          4  \n",
      "4  [45.79, 349.92, 458.36, 480.67, 187.48, 398.59...          5  \n",
      "\n",
      "\n",
      "\n",
      "Cleaned data saved to customer_lifetime.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandi selvam\\AppData\\Local\\Temp\\ipykernel_20996\\756452218.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"customer_lifetime.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project2\\Dataset\\customer_lifetime_data.csv\"  \n",
    "df = pd.read_csv(file_path) \n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"customer_lifetime.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9a2bc",
   "metadata": {},
   "source": [
    "### Data_Cleaning4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d67e830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  User_ID             Name  Age  Gender         Location Signup_Date\n",
      "0  U00001      Charvi Lata   23    Male  Tiruchirappalli  13-04-2024\n",
      "1  U00002  Widisha Sachdev   35    Male      Krishnagiri  30-06-2024\n",
      "2  U00003    Darsh Sanghvi   30  Female          Chennai  29-08-2024\n",
      "3  U00004       Finn Amble   21  Female       Tiruvallur  11-12-2024\n",
      "4  U00005  Madhav Choudhry   35    Male       Dharmapuri  04-11-2024\n",
      "     User_ID         Name  Age  Gender      Location Signup_Date\n",
      "9995  U09996   Naksh Gera   56    Male         Erode  24-02-2024\n",
      "9996  U09997     Eta Iyer   47  Female  Kallakurichi  23-07-2024\n",
      "9997  U09998  Vritti Vora   53    Male       Tenkasi  15-09-2024\n",
      "9998  U09999  Jack Oommen   60  Female      Tiruppur  10-05-2024\n",
      "9999  U10000  Oviya Walla   59    Male    Tiruvallur  04-06-2024\n",
      "\n",
      "\n",
      "\n",
      "dataset columns:\n",
      "Index(['User_ID', 'Name', 'Age', 'Gender', 'Location', 'Signup_Date'], dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Data Types:\n",
      "User_ID        object\n",
      "Name           object\n",
      "Age             int64\n",
      "Gender         object\n",
      "Location       object\n",
      "Signup_Date    object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Missing Values in Each Column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   User_ID      10000 non-null  object\n",
      " 1   Name         10000 non-null  object\n",
      " 2   Age          10000 non-null  int64 \n",
      " 3   Gender       10000 non-null  object\n",
      " 4   Location     10000 non-null  object\n",
      " 5   Signup_Date  10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n",
      "None\n",
      "User_ID        0\n",
      "Name           0\n",
      "Age            0\n",
      "Gender         0\n",
      "Location       0\n",
      "Signup_Date    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "After cleaning (removing rows with only special characters or NaN in any column):\n",
      "  User_ID             Name  Age  Gender         Location Signup_Date\n",
      "0  U00001      Charvi Lata   23    Male  Tiruchirappalli  13-04-2024\n",
      "1  U00002  Widisha Sachdev   35    Male      Krishnagiri  30-06-2024\n",
      "2  U00003    Darsh Sanghvi   30  Female          Chennai  29-08-2024\n",
      "3  U00004       Finn Amble   21  Female       Tiruvallur  11-12-2024\n",
      "4  U00005  Madhav Choudhry   35    Male       Dharmapuri  04-11-2024\n",
      "\n",
      "\n",
      "\n",
      "Cleaned data saved to tamilnadu_Customer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandi selvam\\AppData\\Local\\Temp\\ipykernel_20996\\181519479.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"tamilnadu_Customer.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project2\\Dataset\\tamilnadu_customer_data.csv\"  \n",
    "df = pd.read_csv(file_path) \n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"tamilnadu_Customer.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a491b51",
   "metadata": {},
   "source": [
    "### Data_cleaning5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5e11c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   User_ID TouchpointTimestamp    Channel Campaign_ID       Campaign_Name  \\\n",
      "0     1063    26-06-2025 09:14   Referral    CAMP_460   Referral_Promo_30   \n",
      "1     9829    12-08-2025 18:10   Facebook    CAMP_948   Facebook_Promo_38   \n",
      "2     2383    09-08-2025 21:15  Instagram    CAMP_261  Instagram_Promo_45   \n",
      "3     5829    30-09-2025 13:21    YouTube    CAMP_264     YouTube_Promo_6   \n",
      "4     7104    12-10-2025 03:25    YouTube    CAMP_955    YouTube_Promo_46   \n",
      "\n",
      "     Medium Touchpoint_Type             Page  totaltype  totalmedium  \\\n",
      "0  Referral      Conversion       /thank-you          1            1   \n",
      "1    Social      Impression  /blog/marketing          2            2   \n",
      "2    Social           Visit         /product          3            3   \n",
      "3     Video      Impression        /checkout          4            4   \n",
      "4     Video           Visit  /blog/marketing          5            5   \n",
      "\n",
      "   totalpage  totalchannel  \n",
      "0          1             1  \n",
      "1          2             2  \n",
      "2          3             3  \n",
      "3          4             4  \n",
      "4          5             5  \n",
      "      User_ID TouchpointTimestamp     Channel Campaign_ID  \\\n",
      "9995     3117    04-03-2025 17:13    Referral    CAMP_734   \n",
      "9996     7068    28-03-2025 01:22     YouTube    CAMP_273   \n",
      "9997     3115    24-08-2025 05:44  Google Ads    CAMP_891   \n",
      "9998     2803    25-12-2024 02:14   Instagram    CAMP_171   \n",
      "9999     8170    17-03-2025 21:05  Google Ads    CAMP_239   \n",
      "\n",
      "            Campaign_Name    Medium Touchpoint_Type      Page  totaltype  \\\n",
      "9995     Referral_Promo_6  Referral      Impression     /home         19   \n",
      "9996     YouTube_Promo_16     Video            Open     /home         20   \n",
      "9997  Google Ads_Promo_13      Paid           Visit     /home         21   \n",
      "9998    Instagram_Promo_7    Social           Visit  /pricing         22   \n",
      "9999   Google Ads_Promo_3      Paid            Open     /home         23   \n",
      "\n",
      "      totalmedium  totalpage  totalchannel  \n",
      "9995           19         19            19  \n",
      "9996           20         20            20  \n",
      "9997           21         21            21  \n",
      "9998           22         22            22  \n",
      "9999           23         23            23  \n",
      "\n",
      "\n",
      "\n",
      "dataset columns:\n",
      "Index(['User_ID', 'TouchpointTimestamp', 'Channel', 'Campaign_ID',\n",
      "       'Campaign_Name', 'Medium', 'Touchpoint_Type', 'Page', 'totaltype',\n",
      "       'totalmedium', 'totalpage', 'totalchannel'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Data Types:\n",
      "User_ID                 int64\n",
      "TouchpointTimestamp    object\n",
      "Channel                object\n",
      "Campaign_ID            object\n",
      "Campaign_Name          object\n",
      "Medium                 object\n",
      "Touchpoint_Type        object\n",
      "Page                   object\n",
      "totaltype               int64\n",
      "totalmedium             int64\n",
      "totalpage               int64\n",
      "totalchannel            int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Missing Values in Each Column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   User_ID              10000 non-null  int64 \n",
      " 1   TouchpointTimestamp  10000 non-null  object\n",
      " 2   Channel              10000 non-null  object\n",
      " 3   Campaign_ID          10000 non-null  object\n",
      " 4   Campaign_Name        10000 non-null  object\n",
      " 5   Medium               10000 non-null  object\n",
      " 6   Touchpoint_Type      10000 non-null  object\n",
      " 7   Page                 10000 non-null  object\n",
      " 8   totaltype            10000 non-null  int64 \n",
      " 9   totalmedium          10000 non-null  int64 \n",
      " 10  totalpage            10000 non-null  int64 \n",
      " 11  totalchannel         10000 non-null  int64 \n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 937.6+ KB\n",
      "None\n",
      "User_ID                0\n",
      "TouchpointTimestamp    0\n",
      "Channel                0\n",
      "Campaign_ID            0\n",
      "Campaign_Name          0\n",
      "Medium                 0\n",
      "Touchpoint_Type        0\n",
      "Page                   0\n",
      "totaltype              0\n",
      "totalmedium            0\n",
      "totalpage              0\n",
      "totalchannel           0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "After cleaning (removing rows with only special characters or NaN in any column):\n",
      "   User_ID TouchpointTimestamp    Channel Campaign_ID       Campaign_Name  \\\n",
      "0     1063    26-06-2025 09:14   Referral    CAMP_460   Referral_Promo_30   \n",
      "1     9829    12-08-2025 18:10   Facebook    CAMP_948   Facebook_Promo_38   \n",
      "2     2383    09-08-2025 21:15  Instagram    CAMP_261  Instagram_Promo_45   \n",
      "3     5829    30-09-2025 13:21    YouTube    CAMP_264     YouTube_Promo_6   \n",
      "4     7104    12-10-2025 03:25    YouTube    CAMP_955    YouTube_Promo_46   \n",
      "\n",
      "     Medium Touchpoint_Type             Page  totaltype  totalmedium  \\\n",
      "0  Referral      Conversion       /thank-you          1            1   \n",
      "1    Social      Impression  /blog/marketing          2            2   \n",
      "2    Social           Visit         /product          3            3   \n",
      "3     Video      Impression        /checkout          4            4   \n",
      "4     Video           Visit  /blog/marketing          5            5   \n",
      "\n",
      "   totalpage  totalchannel  \n",
      "0          1             1  \n",
      "1          2             2  \n",
      "2          3             3  \n",
      "3          4             4  \n",
      "4          5             5  \n",
      "\n",
      "\n",
      "\n",
      "Cleaned data saved to touchpoint.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandi selvam\\AppData\\Local\\Temp\\ipykernel_20996\\3726278767.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"touchpoint.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project2\\Dataset\\touchpoint_data.csv\"  \n",
    "df = pd.read_csv(file_path) \n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"touchpoint.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
